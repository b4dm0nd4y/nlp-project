{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "863e31aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './notebooks/vocab2int.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m     28\u001b[39m sys.path.append(\u001b[33m\"\u001b[39m\u001b[33m../src/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mltsm_helper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tokenize_text, LSTMClassifier, BahdanauAttention\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bootcamp/ds-phase-2/nlp-project/notebooks/../src/ltsm_helper.py:84\u001b[39m\n\u001b[32m     79\u001b[39m     padded = padding([text_int], SEQ_LEN)\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m padded\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m f = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./notebooks/vocab2int.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m vocab2int = json.load(f) \n\u001b[32m     86\u001b[39m VOCAB_SIZE = \u001b[38;5;28mlen\u001b[39m(vocab2int) + \u001b[32m1\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './notebooks/vocab2int.json'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#word2vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchutils as tu\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryF1Score, BinaryConfusionMatrix\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "from ltsm_helper import tokenize_text, LSTMClassifier, BahdanauAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96617987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (embedding): Embedding(9767, 100)\n",
       "  (lstm): LSTM(100, 128, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (attention): BahdanauAttention(\n",
       "    (W1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (W2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (v): Linear(in_features=256, out_features=1, bias=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = torch.load(\"bert_best_0.15.pt\", map_location=DEVICE, weights_only=False)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79c90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'огромный спасибо чудесный удаление зуб мудрость мгновение доктор матвеев профессионал большой буква бояться страшно весь занять реально секунда согласиться удаление сразу второй зуб боль страх очень рекомендовать'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04318b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        3.000e+01, 6.000e+00, 9.880e+02, 2.790e+02, 2.400e+01, 1.057e+03,\n",
       "        2.000e+01, 4.638e+03, 1.920e+02, 2.900e+01, 7.310e+02, 2.130e+02,\n",
       "        1.431e+03, 2.000e+00, 4.480e+02, 9.450e+02, 1.705e+03, 7.100e+02,\n",
       "        2.790e+02, 6.800e+01, 1.140e+02, 2.400e+01, 6.600e+01, 6.950e+02,\n",
       "        5.000e+00, 1.860e+02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = tokenize_text(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb5a385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (embedding): Embedding(9767, 100)\n",
       "  (lstm): LSTM(100, 128, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (attention): BahdanauAttention(\n",
       "    (W1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (W2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (v): Linear(in_features=256, out_features=1, bias=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64139046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.320590496063232"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model(torch.tensor(text, dtype=torch.long)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f333d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
